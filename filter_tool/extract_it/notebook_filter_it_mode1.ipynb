{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering internal tide Mode 1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims at filtering the mode 1 Internal Tide **ssh_it1** with a more restrictive frequency than the initial filtering of the Internal Ground Waves (IGW) signal **ssh_igw**. A more restrictive bandpass filter around tidal frequency (12h) is applied : (11h - 13h).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import scipy.fftpack as fp\n",
    "from scipy.signal import find_peaks\n",
    "#from scipy.interpolate import RegularGridInterpolator, griddata\n",
    "from joblib import Parallel\n",
    "from joblib import delayed as jb_delayed\n",
    "from pyinterp import fill, Axis, TemporalAxis, Grid3D, Grid2D\n",
    "from math import *\n",
    "import glob\n",
    "# import xrft\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/bettik/bellemva/src/\")\n",
    "from functions import open_mfdataset_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. - Data import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = glob.glob(\"/bettik/bellemva/ocean_data_challenge/2023e_SSHmapping_HF_Hawaii/dc_ref_eval_coarse/*.nc\")\n",
    "list_files.sort()         \n",
    "ds = open_mfdataset_w(list_files,drop_variables = [\"ssh\",\"ssh_bm\"])#,chunks={'longitude':100,'latitude':100}).chunk({'time':len(list_files)*24})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the zone #\n",
    "lon_min=185;lon_max=205\n",
    "lat_min=15;lat_max=35\n",
    "\n",
    "ds = ds.sel(longitude=slice(lon_min,lon_max),latitude=slice(lat_min,lat_max),drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_it = ds.ssh_it.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. - Internal tide extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_time = ds.ssh_it.time.values\n",
    "nt = array_time.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS # \n",
    "wint = np.ones(3*nt)\n",
    "gaspari = gaspari_cohn(np.arange(0,2*nt,1),nt,nt)\n",
    "wint[:nt]=gaspari[:nt]\n",
    "wint[2*nt:]=gaspari[nt:]\n",
    "\n",
    "dt = 3600 # seconds\n",
    "\n",
    "w = fp.fftfreq(3*nt,dt)# seconds^-1\n",
    "nw = w.size\n",
    "\n",
    "w1 = 1/13/3600\n",
    "w2 = 1/11/3600\n",
    "H = (np.abs(w)>w1) & (np.abs(w)<w2)\n",
    "w_filtered = H*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ocean = np.where(np.invert(np.isnan(ds_it[0,:,:].values))) # indexes of ocean pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESSING # \n",
    "ssh_it_flat = np.array(Parallel(n_jobs=n_workers,backend='multiprocessing')(jb_delayed(extract_it)(ds_it[:,i,j],wint,H) for i,j in zip(idx_ocean[0],idx_ocean[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_time = ds.dims[\"time\"]\n",
    "n_latitude = ds.dims[\"latitude\"]\n",
    "n_longitude = ds.dims[\"longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ds_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARRAY TO STORE THE RESULTS # \n",
    "array_ssh_it = np.nan*np.ones((n_time,n_latitude,n_longitude),dtype=\"float64\")\n",
    "array_ssh_it[:,idx_ocean[0],idx_ocean[1]]=ssh_it_flat.T\n",
    "\n",
    "# np.save(file=\"/bettik/bellemva/MITgcm/MITgcm_it/hawaii_long/ssh_it.npy\",arr=array_ssh_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ssh_it_flat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving internal tide **ssh_it** into xarray DataArray files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELOADING DS FOR THE STRUCTURE # \n",
    "\n",
    "list_files = glob.glob(\"/bettik/bellemva/ocean_data_challenge/2023e_SSHmapping_HF_Hawaii/dc_ref_eval_coarse/*.nc\")\n",
    "list_files.sort()         \n",
    "ds = open_mfdataset_w(list_files)#,chunks={'longitude':100,'latitude':100}).chunk({'time':len(list_files)*24})\n",
    "\n",
    "# selecting the zone #\n",
    "lon_min=185;lon_max=205\n",
    "lat_min=15;lat_max=35\n",
    "\n",
    "ds = ds.sel(longitude=slice(lon_min,lon_max),latitude=slice(lat_min,lat_max),drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array_ssh_it = ds[\"ssh_it\"].copy(data=array_ssh_it)\n",
    "ds[\"ssh_it_12h\"] = data_array_ssh_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_array = np.arange(np.datetime64(\"2012-05-01\"),np.datetime64(\"2012-10-28\"))\n",
    "\n",
    "ds.sel(time=slice(date_array[5],date_array[6]-np.timedelta64(1,\"h\")),drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_array = np.arange(np.datetime64(\"2012-05-01\"),np.datetime64(\"2012-10-28\"))\n",
    "\n",
    "\n",
    "for i in range (len(date_array)) : \n",
    "    \n",
    "    ds_day = ds.sel(time=slice(date_array[i],date_array[i+1]-np.timedelta64(1,\"h\")),drop=True) \n",
    "\n",
    "    ds_day.to_netcdf(\"/bettik/bellemva/ocean_data_challenge/2023e_SSHmapping_HF_Hawaii/dc_ref_eval_coarse/copy/2023e_SSHmapping_HF_Hawaii_eval_\"+date_array[i].astype('str')+\".nc\")\n",
    "\n",
    "    print(date_array[i])\n",
    "\n",
    "ds_day = ds.sel(time=slice(np.datetime64(\"2012-10-27\"),np.datetime64(\"2012-10-28\")-np.timedelta64(1,\"h\")),drop=True) \n",
    "ds_day.to_netcdf(\"/bettik/bellemva/ocean_data_challenge/2023e_SSHmapping_HF_Hawaii/dc_ref_eval_coarse/copy/2023e_SSHmapping_HF_Hawaii_eval_\"+np.datetime64(\"2012-10-27\").astype('str')+\".nc\")\n",
    "\n",
    "       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_it(array_ssh,wint,H): \n",
    "    array_ssh=array_ssh.values\n",
    "    ssh_extended = np.concatenate((np.flip(array_ssh),\n",
    "                                   array_ssh,\n",
    "                                   np.flip(array_ssh)))\n",
    "    ssh_win = wint * ssh_extended \n",
    "    ssh_f_t = fp.fft(ssh_win)\n",
    "    ssh_f_filtered =  H * ssh_f_t\n",
    "    ssh_filtered = np.real(fp.ifft(ssh_f_filtered))[nt:2*nt]\n",
    "    del array_ssh\n",
    "    return ssh_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaspari_cohn(array,distance,center):\n",
    "    \"\"\"\n",
    "    NAME \n",
    "        bfn_gaspari_cohn\n",
    "\n",
    "    DESCRIPTION \n",
    "        Gaspari-Cohn function. @vbellemin.\n",
    "        \n",
    "        Args: \n",
    "            array : array of value whose the Gaspari-Cohn function will be applied\n",
    "            center : centered value of the function \n",
    "            distance : Distance above which the return values are zeros\n",
    "\n",
    "\n",
    "        Returns:  smoothed values \n",
    "            \n",
    "    \"\"\" \n",
    "    if type(array) is float or type(array) is int:\n",
    "        array = np.array([array])\n",
    "    else:\n",
    "        array = array\n",
    "    if distance<=0:\n",
    "        return np.zeros_like(array)\n",
    "    else:\n",
    "        array = 2*np.abs(array-center*np.ones_like(array))/distance\n",
    "        gp = np.zeros_like(array)\n",
    "        i= np.where(array<=1.)[0]\n",
    "        gp[i]=-0.25*array[i]**5+0.5*array[i]**4+0.625*array[i]**3-5./3.*array[i]**2+1.\n",
    "        i =np.where((array>1.)*(array<=2.))[0]\n",
    "        gp[i] = 1./12.*array[i]**5-0.5*array[i]**4+0.625*array[i]**3+5./3.*array[i]**2-5.*array[i]+4.-2./3./array[i]\n",
    "        #if type(r) is float:\n",
    "        #    gp = gp[0]\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cartesian_grid (latitude,longitude,dx):\n",
    "    \"\"\" \n",
    "    Creates a cartesian grid (regular in distance, kilometers) from a geodesic latitude, longitude grid. \n",
    "    The new grid is expressed in latitude, longitude coordinates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    longitude : numpy ndarray \n",
    "        Vector of longitude for geodesic input grid. \n",
    "    latitude : numpy ndarray \n",
    "        Vector of latitude for geodesic input grid. \n",
    "    dx : float \n",
    "        Grid spacing in kilometers. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ENSLAT2D : \n",
    "        2-D numpy ndarray of the latitudes of the points of the cartesian grid \n",
    "    ENSLON2D : \n",
    "        2-D numpy ndarray of the longitudes of the points of the cartesian grid \n",
    "    \"\"\"\n",
    "    km2deg = 1/111\n",
    "\n",
    "    # ENSEMBLE OF LATITUDES # \n",
    "    ENSLAT = np.arange(latitude[0],latitude[-1]+dx*km2deg,dx*km2deg)\n",
    "    range_lon = longitude[-1]-longitude[0]\n",
    "\n",
    "    if longitude.size%2 == 0 : \n",
    "        nstep_lon = floor(range_lon/(dx*km2deg))+2\n",
    "    else : \n",
    "        nstep_lon = ceil(range_lon/(dx*km2deg))+2\n",
    "    ENSLAT2D = np.repeat(np.expand_dims(ENSLAT,axis=1),axis=1,repeats=nstep_lon)\n",
    "\n",
    "    # ENSEMBLE OF LATITUDES # \n",
    "    mid_lon = (longitude[-1]+longitude[0])/2\n",
    "    ENSLON2D=np.zeros_like(ENSLAT2D)\n",
    "\n",
    "    for i in range(len(ENSLAT)):\n",
    "        d_lon = dx*km2deg*(np.cos(np.pi*ENSLAT[0]/180)/np.cos(np.pi*ENSLAT[i]/180))\n",
    "        d_lon_range = np.array([i*d_lon for i in range (1,int(nstep_lon/2)+1)])\n",
    "        lon_left = np.flip(mid_lon-d_lon_range)\n",
    "        lon_right = mid_lon+d_lon_range\n",
    "        ENSLON2D[i,:]=np.concatenate((lon_left,lon_right))\n",
    "\n",
    "    return ENSLAT2D, ENSLON2D, ENSLAT2D.shape[0], ENSLAT2D.shape[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_ssh_it(ssh_it):\n",
    "\n",
    "    x_axis = Axis(ssh_it.longitude.values,is_circle=True)\n",
    "    y_axis = Axis(ssh_it.latitude.values,is_circle=True)\n",
    "    t_axis = TemporalAxis(ssh_it.time.values)\n",
    "\n",
    "    grid = Grid3D(y_axis, x_axis, t_axis, ssh_it.values.transpose(1,2,0))\n",
    "    has_converged, filled = fill.gauss_seidel(grid,num_threads=4)\n",
    "\n",
    "    ssh_it_filled = ssh_it.copy(deep=True,data=filled.transpose(2,0,1)).chunk({'time':1})\n",
    "\n",
    "    dx = 2 # in kilometers, spacing of the grid \n",
    "\n",
    "    ENSLAT2D, ENSLON2D, i_lat, i_lon = create_cartesian_grid(ssh_it_filled.latitude.values,\n",
    "                                                            ssh_it_filled.longitude.values,\n",
    "                                                            dx)\n",
    "\n",
    "    array_cart_ssh = ssh_it_filled.interp(latitude=('z',ENSLAT2D.flatten()),\n",
    "                                        longitude=('z',ENSLON2D.flatten()),\n",
    "                                        ).values\n",
    "\n",
    "    # INTERPOLATION OF NaNs # \n",
    "    x_axis = Axis(np.arange(i_lon))\n",
    "    y_axis = Axis(np.arange(i_lat))\n",
    "    t_axis = TemporalAxis(ssh_it.time.values)\n",
    "\n",
    "    grid = Grid3D(y_axis, x_axis, t_axis, array_cart_ssh.reshape((24,i_lat,i_lon)).transpose(1,2,0))\n",
    "    has_converged, filled = fill.gauss_seidel(grid,num_threads=4)\n",
    "\n",
    "\n",
    "    # CREATION OF DataArray #\n",
    "    cart_ssh_it = xr.DataArray(data=filled.transpose(2,0,1),\n",
    "                            dims=[\"time\",\"y\",\"x\"],\n",
    "                            coords = dict(\n",
    "                                time = ssh_it_filled.time.values,\n",
    "                                #y=([\"y\"],np.arange(i_lat)),\n",
    "                                #x=([\"x\"],np.arange(i_lon))\n",
    "                                y=np.array([i*dx for i in range (i_lat)]),\n",
    "                                x=np.array([i*dx for i in range (i_lon)])\n",
    "                            )).chunk({'time':1})\n",
    "    \n",
    "    return cart_ssh_it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(res,k):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2,figsize=(8,4),dpi=200)\n",
    "\n",
    "    k1 = k[0]#0.0070\n",
    "    k2 = k[1]#0.0126\n",
    "    k3 = k[2]#0.0191\n",
    "    k4 = k[3]#0.0269\n",
    "\n",
    "    ax[0].plot(res.freq_r.values,res.values)\n",
    "    ax[0].set_xlim(0.03,0)\n",
    "    ax[0].set_xlabel(\"Wavenumber [km-1]\")\n",
    "    ax[0].axvline(k1,c='red',linestyle=':')\n",
    "    ax[0].axvline(k2,c='red',linestyle=':')\n",
    "    ax[0].axvline(k3,c='red',linestyle=':')\n",
    "    ax[0].axvline(k4,c='red',linestyle=':')\n",
    "    ax[0].axvline(k1/2,c='red',linestyle='-')\n",
    "    ax[0].axvline((k1+k2)/2,c='red',linestyle='-')\n",
    "    ax[0].axvline((k2+k3)/2,c='red',linestyle='-')\n",
    "    ax[0].axvline((k3+k4)/2,c='red',linestyle='-')\n",
    "    \n",
    "    \n",
    "\n",
    "    ax[1].plot(1/res.freq_r.values,res.values)\n",
    "    ax[1].set_xlim(0,200)\n",
    "    ax[1].set_xlabel(\"Wavelength [km]\")\n",
    "\n",
    "    fig.suptitle(\"Isotropic Power Spectrum of Internal Tides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_massh_bis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
