{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering barotropic tide "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims at filetring High Frequency SSH and removing barotropic tide (large scale signal). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from pyinterp import fill, Axis, TemporalAxis, Grid3D, Grid2D\n",
    "import scipy.fftpack as fp\n",
    "from scipy.interpolate import RegularGridInterpolator, griddata\n",
    "from math import *\n",
    "from dask import delayed,compute\n",
    "from joblib import Parallel\n",
    "from joblib import delayed as jb_delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyinterp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial and final dates : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_date = np.datetime64(\"2014-01-10\")\n",
    "final_date = np.datetime64(\"2014-01-11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths to files : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mask = \"/bettik/PROJECTS/pr-data-ocean/riverama/Datos/CALEDO60/1_mesh_mask_TROPICO12_L125_tr21.nc\" # in numpy .npy format\n",
    "path_to_input = \"/bettik/PROJECTS/pr-data-ocean/riverama/Datos/Filtrage/ssh_hf/ssh_hf_\" # including the file name prefix \n",
    "path_to_save = \"/bettik/PROJECTS/pr-data-ocean/riverama/Datos/Filtrage/ssh_bar/ssh_bar_\" # including the file name prefix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = xr.open_dataset('/bettik/PROJECTS/pr-data-ocean/riverama/Datos/CALEDO60/1_mesh_mask_TROPICO12_L125_tr21.nc',drop_variables={\"x\",\"y\"}) \n",
    "mask = mask.tmaskutil[0,:,:].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cartesian_grid (latitude,longitude,dx):\n",
    "    \"\"\" \n",
    "    Creates a cartesian grid (regular in distance, kilometers) from a geodesic latitude, longitude grid. \n",
    "    The new grid is expressed in latitude, longitude coordinates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    longitude : numpy ndarray \n",
    "        Vector of longitude for geodesic input grid. \n",
    "    latitude : numpy ndarray \n",
    "        Vector of latitude for geodesic input grid. \n",
    "    dx : float \n",
    "        Grid spacing in kilometers. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ENSLAT2D : \n",
    "        2-D numpy ndarray of the latitudes of the points of the cartesian grid \n",
    "    ENSLON2D : \n",
    "        2-D numpy ndarray of the longitudes of the points of the cartesian grid \n",
    "    \"\"\"\n",
    "    km2deg = 1/111\n",
    "\n",
    "    # ENSEMBLE OF LATITUDES # \n",
    "    ENSLAT = np.arange(latitude[0],latitude[-1]+dx*km2deg,dx*km2deg)\n",
    "    range_lon = longitude[-1]-longitude[0]\n",
    "\n",
    "    if longitude.size%2 == 0 : \n",
    "        nstep_lon = floor(range_lon/(dx*km2deg))+2\n",
    "    else : \n",
    "        nstep_lon = ceil(range_lon/(dx*km2deg))+2\n",
    "    ENSLAT2D = np.repeat(np.expand_dims(ENSLAT,axis=1),axis=1,repeats=nstep_lon)\n",
    "\n",
    "    # ENSEMBLE OF LATITUDES # \n",
    "    mid_lon = (longitude[-1]+longitude[0])/2\n",
    "    ENSLON2D=np.zeros_like(ENSLAT2D)\n",
    "\n",
    "    for i in range(len(ENSLAT)):\n",
    "        d_lon = dx*km2deg*(np.cos(np.pi*latitude[0]/180)/np.cos(np.pi*latitude[i]/180))\n",
    "        d_lon_range = np.array([i*d_lon for i in range (1,int(nstep_lon/2)+1)])\n",
    "        lon_left = np.flip(mid_lon-d_lon_range)\n",
    "        lon_right = mid_lon+d_lon_range\n",
    "        ENSLON2D[i,:]=np.concatenate((lon_left,lon_right))\n",
    "\n",
    "    return ENSLAT2D, ENSLON2D, ENSLAT2D.shape[0], ENSLAT2D.shape[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowpass(_lambda,nx,ny,wavenum2D) : \n",
    "    _lowpass = np.zeros((3*ny,3*nx))\n",
    "    for i in range (3*ny):\n",
    "        for j in range(3*nx):\n",
    "            if wavenum2D[i,j]<1/_lambda:\n",
    "                _lowpass[i,j] = 1\n",
    "    return _lowpass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend(ssh,nx,ny):\n",
    "    ssh_extended = np.empty((3*ny,3*nx))\n",
    "    ssh_extended[ny:2*ny,nx:2*nx] = +ssh\n",
    "    ssh_extended[0:ny,nx:2*nx] = +ssh[::-1,:]\n",
    "    ssh_extended[2*ny:3*ny,nx:2*nx] = +ssh[::-1,:]\n",
    "    ssh_extended[:,0:nx] = ssh_extended[:,nx:2*nx][:,::-1]\n",
    "    ssh_extended[:,2*nx:3*nx] = ssh_extended[:,nx:2*nx][:,::-1]\n",
    "    return ssh_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaspari_cohn(array,distance,center):\n",
    "    \"\"\"\n",
    "    NAME \n",
    "        bfn_gaspari_cohn\n",
    "\n",
    "    DESCRIPTION \n",
    "        Gaspari-Cohn function. @vbellemin.\n",
    "        \n",
    "        Args: \n",
    "            array : array of value whose the Gaspari-Cohn function will be applied\n",
    "            center : centered value of the function \n",
    "            distance : Distance above which the return values are zeros\n",
    "\n",
    "\n",
    "        Returns:  smoothed values \n",
    "            \n",
    "    \"\"\" \n",
    "    if type(array) is float or type(array) is int:\n",
    "        array = np.array([array])\n",
    "    else:\n",
    "        array = array\n",
    "    if distance<=0:\n",
    "        return np.zeros_like(array)\n",
    "    else:\n",
    "        array = 2*np.abs(array-center*np.ones_like(array))/distance\n",
    "        gp = np.zeros_like(array)\n",
    "        i= np.where(array<=1.)[0]\n",
    "        gp[i]=-0.25*array[i]**5+0.5*array[i]**4+0.625*array[i]**3-5./3.*array[i]**2+1.\n",
    "        i =np.where((array>1.)*(array<=2.))[0]\n",
    "        gp[i] = 1./12.*array[i]**5-0.5*array[i]**4+0.625*array[i]**3+5./3.*array[i]**2-5.*array[i]+4.-2./3./array[i]\n",
    "        #if type(r) is float:\n",
    "        #    gp = gp[0]\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spatial_window(nx,ny):\n",
    "    result = np.ones((3*ny,3*nx))\n",
    "    \n",
    "    gaspari_x = np.expand_dims(gaspari_cohn(np.arange(2*nx),nx,nx),axis=0)\n",
    "    gaspari_y = np.expand_dims(gaspari_cohn(np.arange(2*ny),ny,ny),axis=1)\n",
    "\n",
    "    #paving edges with gaspari-cohn\n",
    "    result[2*ny:,nx:2*nx] = np.repeat(gaspari_y[ny:,:],repeats=nx,axis=1)\n",
    "    result[:ny,nx:2*nx] = np.repeat(gaspari_y[:ny,:],repeats=nx,axis=1)\n",
    "    result[ny:2*ny,0:nx] = np.repeat(gaspari_x[:,:nx],repeats=ny,axis=0)\n",
    "    result[ny:2*ny,2*nx:] = np.repeat(gaspari_x[:,nx:],repeats=ny,axis=0)\n",
    "\n",
    "    #paving corners with gaspari-cohn\n",
    "    result[2*ny:,2*nx:]=gaspari_y[ny:,:]*gaspari_x[:,nx:]\n",
    "    result[:ny,:nx]=gaspari_y[:ny,:]*gaspari_x[:,:nx]\n",
    "    result[2*ny:,:nx]=gaspari_y[ny:,:]*gaspari_x[:,:nx]\n",
    "    result[:ny,2*nx:]=gaspari_y[:ny,:]*gaspari_x[:,nx:]\n",
    "\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bar_tide(ssh0,dx):\n",
    "\n",
    "    nx = ssh0.shape[1]\n",
    "    ny = ssh0.shape[0]\n",
    "\n",
    "    kx = np.fft.fftfreq(3*nx,dx) # km\n",
    "    ky = np.fft.fftfreq(3*ny,dx) # km\n",
    "    k, l = np.meshgrid(kx,ky)\n",
    "    wavenum2D = np.sqrt(k**2 + l**2)\n",
    "\n",
    "    lambda_bar = 400\n",
    "    lowpass_bar = lowpass(lambda_bar,nx,ny,wavenum2D)\n",
    "\n",
    "    window = create_spatial_window(nx,ny)\n",
    "\n",
    "    ssh = extend(ssh0,nx,ny)\n",
    "    ssh = ssh * window\n",
    "    ssh_freq = fp.fft2(ssh)\n",
    "    ssh_freq_filtered = lowpass_bar * ssh_freq\n",
    "    ssh_filtered = np.real(fp.ifft2(ssh_freq_filtered))[ny:2*ny,nx:2*nx]\n",
    "\n",
    "    return ssh_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formating(i):\n",
    "    if i//10 == 0 : \n",
    "        return \"0\"+str(i)\n",
    "    else : \n",
    "        return str(i) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_tide(month):\n",
    "\n",
    "    ds = xr.open_dataset(path_to_input+formating(month)+\".nc\")\n",
    "    # mask = np.load(path_to_mask)\n",
    "    ds = ds.rename({'__xarray_dataarray_variable__': 'ssh_hf'})\n",
    "    # print(ds)\n",
    "    \n",
    "    # PROCESSING #\n",
    "\n",
    "    ssh_hf = ds.ssh_hf.where(mask==False,np.nan)\n",
    "\n",
    "    ssh_hf = ssh_hf.coarsen(x=4, y=4, boundary='trim').mean()\n",
    "    ssh_hf = ssh_hf.load().chunk({'time_counter': 1})\n",
    "    # print('****** ssh_hf ******')\n",
    "    # print(ssh_hf)\n",
    "    \n",
    "    x_axis = Axis(ssh_hf.x.values,is_circle=True)\n",
    "    y_axis = Axis(ssh_hf.y.values,is_circle=True)\n",
    "    t_axis = TemporalAxis(ssh_hf.time_counter.values)\n",
    "    # print('****** x_axis,y_axis,t_axis ******')\n",
    "    # print(x_axis,y_axis,t_axis)\n",
    "    \n",
    "    grid = Grid3D(y_axis, x_axis, t_axis, ssh_hf.values.transpose(1,2,0))\n",
    "    has_converged, filled = fill.gauss_seidel(grid,num_threads=16)\n",
    "\n",
    "    ssh_hf_filled = ssh_hf.copy(deep=True,data=filled.transpose(2,0,1)).chunk({'time_counter':1})\n",
    "    # print('****** ssh_hf_filled ******')\n",
    "    # print(ssh_hf_filled)\n",
    "\n",
    "    # TO CARTESIAN GRID #\n",
    "\n",
    "    dx = 10 # in kilometers, spacing of the grid \n",
    "\n",
    "    ENSLAT2D, ENSLON2D, i_lat, i_lon = create_cartesian_grid(ssh_hf_filled.lat[:,0].values,\n",
    "                                                            ssh_hf_filled.lon[0,:].values,\n",
    "                                                            dx)\n",
    "\n",
    "    array_cart_ssh = ssh_hf_filled.interp(y=('z',ENSLAT2D.flatten()),\n",
    "                                        x=('z',ENSLON2D.flatten()),\n",
    "                                        ).values\n",
    "\n",
    "    #INTERPOLATION OF NaNs # \n",
    "    x_axis = Axis(np.arange(i_lon))\n",
    "    y_axis = Axis(np.arange(i_lat))\n",
    "    t_axis = TemporalAxis(ssh_hf.time_counter.values)\n",
    "\n",
    "    num_time_steps = ssh_hf.time_counter.size\n",
    "    \n",
    "    grid = Grid3D(y_axis, x_axis, t_axis, array_cart_ssh.reshape((num_time_steps,i_lat,i_lon)).transpose(1,2,0))\n",
    "    has_converged, filled = fill.gauss_seidel(grid,num_threads=16)\n",
    "\n",
    "    mask_cart = np.isnan(array_cart_ssh[0].reshape((i_lat,i_lon)))\n",
    "\n",
    "    cart_ssh_hf = xr.DataArray(data=filled.transpose(2,0,1),\n",
    "                            dims=[\"time_counter\",\"y\",\"x\"],\n",
    "                            coords = dict(\n",
    "                                time_counter = ssh_hf_filled.time_counter.values,\n",
    "                                y=([\"y\"],np.arange(i_lat)),\n",
    "                                x=([\"x\"],np.arange(i_lon))\n",
    "                            )).chunk({'time_counter':1})\n",
    "    \n",
    "    \n",
    "    # EXTRACTING BAROTROPIC TIDE # \n",
    "    cart_ssh_filtered = np.array(Parallel(n_jobs=16,backend='multiprocessing')(jb_delayed(extract_bar_tide)(cart_ssh_hf[i].values,dx) for i in range(num_time_steps)))\n",
    "\n",
    "    lon2d, lat2d = np.meshgrid(ssh_hf.lon.values, ssh_hf.lat.values)\n",
    "\n",
    "    geo_filtered = np.array(Parallel(n_jobs=16,backend='multiprocessing')(jb_delayed(griddata)(np.array([ENSLAT2D.flatten(),ENSLON2D.flatten()]).T,\n",
    "                                        cart_ssh_filtered[i].flatten(),\n",
    "                                        (lat2d,lon2d),'cubic') for i in range(num_time_steps)))\n",
    "    \n",
    "    print('Extraction of the barotropic tide for the month of '+formating(month)+' is done !')\n",
    "\n",
    "    # FINAL FILE CREATION # \n",
    "\n",
    "    ssh_filtered = ssh_hf.copy(deep=True,data=cart_ssh_filtered).chunk({'time_counter':1}) #changer geo_filtered par cart_ssh_filtered\n",
    "    \n",
    "    ssh_filtered = ssh_filtered.interp_like(ds,kwargs={\"fill_value\": \"extrapolate\"}) #interpolation \n",
    "\n",
    "    ssh_filtered = ssh_filtered.where(mask==False,np.nan)\n",
    "\n",
    "    ssh_filtered = ssh_filtered.rename(\"ssh_bar\")\n",
    "\n",
    "    ssh_filtered.to_netcdf(path_to_save+date.astype('str').replace('-','')+\".nc\")\n",
    "    \n",
    "    print('File for the month of '+formating(month)+' has been saved !')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call to functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_month = np.arange(1,13,1)\n",
    "\n",
    "for month in array_month[:1]:\n",
    "    create_bar_tide(month)\n",
    "    print(month,\" : done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_tide(month, start_time, end_time):\n",
    "    # Path should be configured to the specific month if not dynamically set\n",
    "    ds = xr.open_dataset(path_to_input + formating(month) + \".nc\")\n",
    "    print('open ds: ok')\n",
    "    \n",
    "    ds = ds.rename({'__xarray_dataarray_variable__': 'ssh_hf'})\n",
    "    \n",
    "    # Filter by time range\n",
    "    ds = ds.sel(time_counter=slice(start_time, end_time))\n",
    "    print('slide ds: ok')\n",
    "    # PROCESSING #\n",
    "    print('#### PROCESSING ####')\n",
    "    \n",
    "    ssh_hf = ds.ssh_hf.where(mask==False,np.nan)\n",
    "    print('mask: ok')\n",
    "    \n",
    "    ssh_hf = ssh_hf.coarsen(x=4, y=4, boundary='trim').mean()\n",
    "    print('coarsen: ok')\n",
    "    \n",
    "    ssh_hf = ssh_hf.load().chunk({'time_counter': 2})\n",
    "    print('chunk time_counter: ok')\n",
    "    \n",
    "    x_axis = Axis(ssh_hf.x.values,is_circle=True)\n",
    "    y_axis = Axis(ssh_hf.y.values,is_circle=True)\n",
    "    t_axis = TemporalAxis(ssh_hf.time_counter.values)\n",
    "    print('x_axis,y_axis,t_axis: ok')\n",
    "    \n",
    "    grid = Grid3D(y_axis, x_axis, t_axis, ssh_hf.values.transpose(1,2,0))\n",
    "    print('grid: ok')\n",
    "    has_converged, filled = fill.gauss_seidel(grid,num_threads=16)\n",
    "    print(has_converged)\n",
    "    print('filled: ok')\n",
    "    \n",
    "    ssh_hf_filled = ssh_hf.copy(deep=True,data=filled.transpose(2,0,1)).chunk({'time_counter':2})\n",
    "    print('copy: ok')\n",
    "\n",
    "    # TO CARTESIAN GRID #\n",
    "    print('#### TO CARTESIAN GRID ####')\n",
    "    \n",
    "    dx = 10 # in kilometers, spacing of the grid \n",
    "\n",
    "    ENSLAT2D, ENSLON2D, i_lat, i_lon = create_cartesian_grid(ssh_hf_filled.lat[:,0].values,\n",
    "                                                            ssh_hf_filled.lon[0,:].values,\n",
    "                                                            dx)\n",
    "    print('ENSLAT2D, ENSLON2D, i_lat, i_lon: ok')\n",
    "    \n",
    "    array_cart_ssh = ssh_hf_filled.interp(y=('z',ENSLAT2D.flatten()),\n",
    "                                        x=('z',ENSLON2D.flatten()),\n",
    "                                        ).values\n",
    "    print('array_cart_ssh: ok')\n",
    "    \n",
    "    #INTERPOLATION OF NaNs #\n",
    "    print('#### INTERPOLATION OF NaNs ####')\n",
    "    x_axis = Axis(np.arange(i_lon))\n",
    "    y_axis = Axis(np.arange(i_lat))\n",
    "    t_axis = TemporalAxis(ssh_hf.time_counter.values)\n",
    "    print('x_axis,y_axis,t_axis: ok')\n",
    "    \n",
    "    #num_time_steps = ssh_hf.time_counter.size\n",
    "    num_time_steps = 2\n",
    "    \n",
    "    grid = Grid3D(y_axis, x_axis, t_axis, array_cart_ssh.reshape((num_time_steps,i_lat,i_lon)).transpose(1,2,0))\n",
    "    print('grid: ok')\n",
    "    \n",
    "    has_converged, filled = fill.gauss_seidel(grid,num_threads=1)\n",
    "    print(has_converged)\n",
    "    print('filled: ok')\n",
    "    \n",
    "    mask_cart = np.isnan(array_cart_ssh[0].reshape((i_lat,i_lon)))\n",
    "    print('mask_cart: ok')\n",
    "    \n",
    "    cart_ssh_hf = xr.DataArray(data=filled.transpose(2,0,1),\n",
    "                            dims=[\"time_counter\",\"y\",\"x\"],\n",
    "                            coords = dict(\n",
    "                                time_counter = ssh_hf_filled.time_counter.values,\n",
    "                                y=([\"y\"],np.arange(i_lat)),\n",
    "                                x=([\"x\"],np.arange(i_lon))\n",
    "                            )).chunk({'time_counter':1})\n",
    "    print('cart_ssh_hf: ok')\n",
    "    \n",
    "    # EXTRACTING BAROTROPIC TIDE # \n",
    "    print('#### EXTRACTING BAROTROPIC TIDE ####')\n",
    "    \n",
    "    cart_ssh_filtered = np.array(Parallel(n_jobs=1,backend='multiprocessing')(jb_delayed(extract_bar_tide)(cart_ssh_hf[i].values,dx) for i in range(num_time_steps)))\n",
    "    print('cart_ssh_filtered: ok')\n",
    "    \n",
    "    lon2d, lat2d = np.meshgrid(ssh_hf.lon.values, ssh_hf.lat.values)\n",
    "    print('lon2d, lat2d: ok') ## printed\n",
    "    \n",
    "    geo_filtered = np.array(Parallel(n_jobs=1,backend='multiprocessing')(jb_delayed(griddata)(np.array([ENSLAT2D.flatten(),ENSLON2D.flatten()]).T,\n",
    "                                        cart_ssh_filtered[i].flatten(),\n",
    "                                        (lat2d,lon2d),'cubic') for i in range(num_time_steps)))\n",
    "    print('geo_filtered: ok')\n",
    "    \n",
    "    # FINAL FILE CREATION # \n",
    "\n",
    "    ssh_filtered = ssh_hf.copy(deep=True,data=cart_ssh_filtered).chunk({'time_counter':2}) #changer geo_filtered par cart_ssh_filtered\n",
    "    print('ssh_filtered: ok')\n",
    "    \n",
    "    ssh_filtered = ssh_filtered.interp_like(ds,kwargs={\"fill_value\": \"extrapolate\"}) #interpolation \n",
    "    print('interp_like: ok')\n",
    "    \n",
    "    ssh_filtered = ssh_filtered.where(mask==False,np.nan)\n",
    "    print('where: ok')\n",
    "    \n",
    "    ssh_filtered = ssh_filtered.rename(\"ssh_bar\")\n",
    "    print('rename: ok')\n",
    "    \n",
    "    ssh_filtered.to_netcdf(path_to_save+date.astype('str').replace('-','')+\".nc\")\n",
    "    print('to_netcdf: ok') \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open ds: ok\n",
      "slide ds: ok\n",
      "#### PROCESSING ####\n",
      "mask: ok\n",
      "coarsen: ok\n",
      "chunk time_counter: ok\n",
      "x_axis,y_axis,t_axis: ok\n",
      "grid: ok\n",
      "True\n",
      "filled: ok\n",
      "copy: ok\n",
      "#### TO CARTESIAN GRID ####\n",
      "ENSLAT2D, ENSLON2D, i_lat, i_lon: ok\n",
      "array_cart_ssh: ok\n",
      "#### INTERPOLATION OF NaNs ####\n",
      "x_axis,y_axis,t_axis: ok\n",
      "grid: ok\n",
      "True\n",
      "filled: ok\n",
      "mask_cart: ok\n",
      "cart_ssh_hf: ok\n",
      "#### EXTRACTING BAROTROPIC TIDE ####\n",
      "cart_ssh_filtered: ok\n",
      "lon2d, lat2d: ok\n"
     ]
    }
   ],
   "source": [
    "month = 2  # Example month (January)\n",
    "start_time = np.datetime64(\"2014-02-10T00:30:00\")\n",
    "end_time = np.datetime64(\"2014-02-10T01:30:00\")\n",
    "create_bar_tide(month, start_time, end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_tide(month, start_time, end_time):\n",
    "    # Path should be configured to the specific month if not dynamically set\n",
    "    ds = xr.open_dataset(path_to_input + formating(month) + \".nc\")\n",
    "    print('open ds: ok')\n",
    "    \n",
    "    ds = ds.rename({'__xarray_dataarray_variable__': 'ssh_hf'})\n",
    "    \n",
    "    # Filter by time range\n",
    "    ds = ds.sel(time_counter=slice(start_time, end_time))\n",
    "    print('slide ds: ok')\n",
    "    # PROCESSING #\n",
    "    print('#### PROCESSING ####')\n",
    "    \n",
    "    ssh_hf = ds.ssh_hf.where(mask==False,np.nan)\n",
    "    print('mask: ok')\n",
    "    \n",
    "    ssh_hf = ssh_hf.coarsen(x=4, y=4, boundary='trim').mean()\n",
    "    print('coarsen: ok')\n",
    "    \n",
    "    ssh_hf = ssh_hf.load().chunk({'time_counter': 2})\n",
    "    print('chunk time_counter: ok')\n",
    "    \n",
    "    x_axis = Axis(ssh_hf.x.values,is_circle=True)\n",
    "    y_axis = Axis(ssh_hf.y.values,is_circle=True)\n",
    "    t_axis = TemporalAxis(ssh_hf.time_counter.values)\n",
    "    print('x_axis,y_axis,t_axis: ok')\n",
    "    \n",
    "    grid = Grid3D(y_axis, x_axis, t_axis, ssh_hf.values.transpose(1,2,0))\n",
    "    print('grid: ok')\n",
    "    has_converged, filled = fill.gauss_seidel(grid,num_threads=16)\n",
    "    print(has_converged)\n",
    "    print('filled: ok')\n",
    "    \n",
    "    ssh_hf_filled = ssh_hf.copy(deep=True,data=filled.transpose(2,0,1)).chunk({'time_counter':2})\n",
    "    print('copy: ok')\n",
    "\n",
    "    # TO CARTESIAN GRID #\n",
    "    print('#### TO CARTESIAN GRID ####')\n",
    "    \n",
    "    dx = 10 # in kilometers, spacing of the grid \n",
    "\n",
    "    ENSLAT2D, ENSLON2D, i_lat, i_lon = create_cartesian_grid(ssh_hf_filled.lat[:,0].values,\n",
    "                                                            ssh_hf_filled.lon[0,:].values,\n",
    "                                                            dx)\n",
    "    print('ENSLAT2D, ENSLON2D, i_lat, i_lon: ok')\n",
    "    \n",
    "    array_cart_ssh = ssh_hf_filled.interp(y=('z',ENSLAT2D.flatten()),\n",
    "                                        x=('z',ENSLON2D.flatten()),\n",
    "                                        ).values\n",
    "    print('array_cart_ssh: ok')\n",
    "    \n",
    "    #INTERPOLATION OF NaNs #\n",
    "    print('#### INTERPOLATION OF NaNs ####')\n",
    "    x_axis = Axis(np.arange(i_lon))\n",
    "    y_axis = Axis(np.arange(i_lat))\n",
    "    t_axis = TemporalAxis(ssh_hf.time_counter.values)\n",
    "    print('x_axis,y_axis,t_axis: ok')\n",
    "    \n",
    "    #num_time_steps = ssh_hf.time_counter.size\n",
    "    num_time_steps = 2\n",
    "    \n",
    "    grid = Grid3D(y_axis, x_axis, t_axis, array_cart_ssh.reshape((num_time_steps,i_lat,i_lon)).transpose(1,2,0))\n",
    "    print('grid: ok')\n",
    "    \n",
    "    has_converged, filled = fill.gauss_seidel(grid,num_threads=1)\n",
    "    print(has_converged)\n",
    "    print('filled: ok')\n",
    "    \n",
    "    mask_cart = np.isnan(array_cart_ssh[0].reshape((i_lat,i_lon)))\n",
    "    print('mask_cart: ok')\n",
    "    \n",
    "    cart_ssh_hf = xr.DataArray(data=filled.transpose(2,0,1),\n",
    "                            dims=[\"time_counter\",\"y\",\"x\"],\n",
    "                            coords = dict(\n",
    "                                time_counter = ssh_hf_filled.time_counter.values,\n",
    "                                y=([\"y\"],np.arange(i_lat)),\n",
    "                                x=([\"x\"],np.arange(i_lon))\n",
    "                            )).chunk({'time_counter':1})\n",
    "    print('cart_ssh_hf: ok')\n",
    "    \n",
    "    # EXTRACTING BAROTROPIC TIDE # \n",
    "    print('#### EXTRACTING BAROTROPIC TIDE ####')\n",
    "    \n",
    "    cart_ssh_filtered = np.array(Parallel(n_jobs=1,backend='multiprocessing')(jb_delayed(extract_bar_tide)(cart_ssh_hf[i].values,dx) for i in range(num_time_steps)))\n",
    "    print('cart_ssh_filtered: ok')\n",
    "    \n",
    "    lon2d, lat2d = np.meshgrid(ssh_hf.lon.values, ssh_hf.lat.values)\n",
    "    print('lon2d, lat2d: ok') ## printed\n",
    "    \n",
    "    geo_filtered = np.array(Parallel(n_jobs=1,backend='multiprocessing')(jb_delayed(griddata)(np.array([ENSLAT2D.flatten(),ENSLON2D.flatten()]).T,\n",
    "                                        cart_ssh_filtered[i].flatten(),\n",
    "                                        (lat2d,lon2d),'cubic') for i in range(num_time_steps)))\n",
    "    print('geo_filtered: ok')\n",
    "    \n",
    "    # FINAL FILE CREATION # \n",
    "\n",
    "    ssh_filtered = ssh_hf.copy(deep=True,data=cart_ssh_filtered).chunk({'time_counter':2}) #changer geo_filtered par cart_ssh_filtered\n",
    "    print('ssh_filtered: ok')\n",
    "    \n",
    "    ssh_filtered = ssh_filtered.interp_like(ds,kwargs={\"fill_value\": \"extrapolate\"}) #interpolation \n",
    "    print('interp_like: ok')\n",
    "    \n",
    "    ssh_filtered = ssh_filtered.where(mask==False,np.nan)\n",
    "    print('where: ok')\n",
    "    \n",
    "    ssh_filtered = ssh_filtered.rename(\"ssh_bar\")\n",
    "    print('rename: ok')\n",
    "    \n",
    "    ssh_filtered.to_netcdf(path_to_save+date.astype('str').replace('-','')+\".nc\")\n",
    "    print('to_netcdf: ok') \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorganizing the result files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command is adding the files saved in *path_to_save* into the existing files of *path_to_general_files*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_general_files = \"/bettik/bellemva/MITgcm/MITgcm_filtered_final/MITgcm_filt_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = np.arange(init_date,final_date)\n",
    "\n",
    "# deleting the content of file.sh \n",
    "file = open(\"./nco_bash.sh\",\"w\")\n",
    "file.close()\n",
    "\n",
    "for d in dates:\n",
    "\n",
    "    command = \"ncks -h -A \"\n",
    "\n",
    "    command += path_to_save+d.astype('str').replace(\"-\",\"\")+\".nc \"\n",
    "\n",
    "    command += path_to_general_files+d.astype('str').replace(\"-\",\"\")+\".nc \\n\"\n",
    "    \n",
    "    file = open(\"./nco_bash.sh\",\"a\")\n",
    "    \n",
    "    file.write(command)\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /applis/site/nix.sh\n",
    "!chmod +x ./nco_bash.sh\n",
    "!./nco_bash.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the *ssh_cor* and *ssh_igw* variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = np.arange(init_date,final_date)\n",
    "\n",
    "# deleting the content of file.sh \n",
    "file = open(\"./nco_bash.sh\",\"w\")\n",
    "file.close()\n",
    "\n",
    "for d in dates:\n",
    "\n",
    "    command = \"ncap2 -h -A -s \\\"ssh_cor=ssh_dedac-ssh_bar\\\" \"\n",
    "\n",
    "    command += path_to_general_files+d.astype('str').replace(\"-\",\"\")+\".nc \"\n",
    "\n",
    "    command += path_to_general_files+d.astype('str').replace(\"-\",\"\")+\".nc \\n\"\n",
    "\n",
    "    command += \"ncap2 -h -A -s \\\"ssh_igw=ssh_hf-ssh_bar\\\" \"\n",
    "\n",
    "    command += path_to_general_files+d.astype('str').replace(\"-\",\"\")+\".nc \"\n",
    "\n",
    "    command += path_to_general_files+d.astype('str').replace(\"-\",\"\")+\".nc \\n\"\n",
    "    \n",
    "    file = open(\"./nco_bash.sh\",\"a\")\n",
    "    \n",
    "    file.write(command)\n",
    "\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /applis/site/nix.sh\n",
    "!chmod +x ./nco_bash.sh\n",
    "!./nco_bash.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = np.arange(np.datetime64(\"2012-06-01\"),np.datetime64(\"2012-07-01\"))\n",
    "\n",
    "# deleting the content of file.sh \n",
    "file = open(\"./nco_bash.sh\",\"w\")\n",
    "file.close()\n",
    "\n",
    "\n",
    "for d in dates:\n",
    "\n",
    "    command = \"ncks -h -C -O -x -v ssh_it \"\n",
    "\n",
    "    command += path_to_general_files+d.astype('str').replace(\"-\",\"\")+\".nc \"\n",
    "\n",
    "    command += path_to_general_files+d.astype('str').replace(\"-\",\"\")+\".nc \\n\"\n",
    "    \n",
    "    file = open(\"./nco_bash.sh\",\"a\")\n",
    "    \n",
    "    file.write(command)\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo-forge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
