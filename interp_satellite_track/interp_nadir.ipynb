{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File to generate Nadir OSSE tracks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import xarray as xr\n",
    "import glob \n",
    "import os \n",
    "from scipy import interpolate\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy\n",
    "\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel\n",
    "from joblib import delayed as jb_delayed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choice of the OSSE zone between *crossover_CCS*, *crossover_centerpacific* and *crossover_hawaii*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ZONE OF CROSSOVERS ###\n",
    "\n",
    "#zone = \"crossover_CCS\"\n",
    "#zone = \"crossover_centerpacific\"\n",
    "#zone = \"crossover_hawaii\"\n",
    "\n",
    "### ZONE OF IMAGINARY CROSSOVERS ### \n",
    "\n",
    "zone = \"hawaii\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choice of the variables to integrate in the interpolated measurements among : \n",
    "- *ssh_cor* : Total DAC corrected SSH, renamed *ssh* in the output dataset \n",
    "- *ssh_bm* : Balanced Motion,\n",
    "- *ssh_it1* : 1st Mode Internal Tide, \n",
    "- *ssh_it2* : 2nd Mode Internal Tide, \n",
    "- *ssh_it3* : 3d Mode Internal Tide, \n",
    "- *ssh_it_tot* : Total Internal Tide,\n",
    "- *ssh_it1_coherent* : Coherent part of the 1st Mode Internal Tide. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_variables = [\"ssh_cor\",\"ssh_bm\",\"ssh_it1\"]\n",
    "dic_attrs = dict({\"ssh\":\"Total DAC corrected SSH.\",\n",
    "                  \"ssh_bm\":\"Balanced Motion.\",\n",
    "                  \"ssh_it1\":\"1st Mode Internal Tide.\",\n",
    "                  \"ssh_it2\":\"2nd Mode Internal Tide.\",\n",
    "                  \"ssh_it3\":\"3d Mode Internal Tide.\",\n",
    "                  \"ssh_it_tot\":\"Total Internal Tide.\",\n",
    "                  \"ssh_it1_coherent\":\"Coherent part of the 1st Mode Internal Tide.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the coordinates limits : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zone == \"crossover_CCS\":\n",
    "    lon_min = 225; lon_max = 245;lat_min = 25; lat_max = 45;\n",
    "elif zone == \"crossover_centerpacific\":\n",
    "    lon_min = 200; lon_max = 220;lat_min = 25; lat_max = 45;\n",
    "elif zone == \"crossover_hawaii\":\n",
    "    lon_min = 180; lon_max = 200;lat_min = 25; lat_max = 45;\n",
    "elif zone == \"hawaii\":\n",
    "    lon_min = 185; lon_max = 205;lat_min = 15; lat_max = 35;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. - Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_satellite_data(date,str_satellite):\n",
    "\n",
    "    dir_input = \"/bettik/bellemva/satellite_track\"\n",
    "\n",
    "    date_split = date.astype('str').split(\"-\")\n",
    "\n",
    "    path_obs = os.path.join(dir_input,str_satellite,\"2019\",\"dt_global_*\"+date_split[1]+date_split[2]+\"*.nc\")\n",
    "    ds = xr.open_mfdataset(path_obs,combine='nested',concat_dim=\"time\")\n",
    "\n",
    "    lon_nad = ds.longitude\n",
    "    lat_nad = ds.latitude\n",
    "\n",
    "    mask = (lon_nad>lon_min)*(lon_nad<lon_max)*(lat_nad>lat_min)*(lat_nad<lat_max)\n",
    "\n",
    "    ds = ds.where(mask.compute(),drop=True)\n",
    "\n",
    "    empty_array = xr.DataArray(np.empty(ds.time.shape), dims=['time'])\n",
    "\n",
    "    track = xr.Dataset({'point':(('time'),empty_array.data)},\n",
    "                       coords={'time':('time',ds.time.values),'latitude':('latitude',ds.latitude.values),'longitude':('longitude',ds.longitude.values)})\n",
    "    \n",
    "    new_time_array = np.array([np.datetime64(t.astype('str').replace(\"2019\",\"2012\")).astype('datetime64[ns]') for t in track.time.values])\n",
    "    new_time_array_float = np.array([t.astype('float64') for t in new_time_array])\n",
    "    track = track.assign_coords({\"time\":new_time_array_float})\n",
    "\n",
    "    return track, new_time_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_model_data(date,var,omit_next_step=False):\n",
    "\n",
    "    if \"ssh_it\" in var : # variable of internal tide ssh, contained inside MITgcm_it directory \n",
    "        dir_input_ssh = f\"/bettik/bellemva/MITgcm/MITgcm_it/{zone}/\"\n",
    "        if omit_next_step:\n",
    "            path = os.path.join(dir_input_ssh,\"MITgcm_it_\"+date.astype('str').replace(\"-\",\"\")+\".nc\")\n",
    "        else : \n",
    "            path = []\n",
    "            path.append(os.path.join(dir_input_ssh,\"MITgcm_it_\"+date.astype('str').replace(\"-\",\"\")+\".nc\"))\n",
    "            path.append(os.path.join(dir_input_ssh,\"MITgcm_it_\"+(date+np.timedelta64(1,\"D\")).astype('str').replace(\"-\",\"\")+\".nc\"))\n",
    "    else : \n",
    "        dir_input_ssh = f\"/bettik/bellemva/MITgcm/MITgcm_filtered_final\"\n",
    "        if omit_next_step:\n",
    "            path = os.path.join(dir_input_ssh,\"MITgcm_filt_\"+date.astype('str').replace(\"-\",\"\")+\".nc\")\n",
    "        else :  \n",
    "            path = []\n",
    "            path.append(os.path.join(dir_input_ssh,\"MITgcm_filt_\"+date.astype('str').replace(\"-\",\"\")+\".nc\"))\n",
    "            path.append(os.path.join(dir_input_ssh,\"MITgcm_filt_\"+(date+np.timedelta64(1,\"D\")).astype('str').replace(\"-\",\"\")+\".nc\"))\n",
    "    if omit_next_step:\n",
    "        ds_ssh = xr.open_dataset(path)\n",
    "    else :\n",
    "        ds_ssh = xr.open_mfdataset(path,combine=\"nested\",concat_dim=\"time\")\n",
    "        ds_ssh = ds_ssh.sel(longitude = slice(lon_min,lon_max),latitude=slice(lat_min,lat_max),drop=True)\n",
    "\n",
    "    time_array_float = np.array([t.astype(\"datetime64[ns]\").astype('float64') for t in ds_ssh.time.values])\n",
    "    ds_ssh = ds_ssh.assign_coords({\"time\":time_array_float})\n",
    "\n",
    "    if omit_next_step:\n",
    "        finterp = interpolate.RegularGridInterpolator([ds_ssh.time.values[0:24],ds_ssh.latitude.values,ds_ssh.longitude.values],\n",
    "                                                ds_ssh[var].values[0:24],\n",
    "                                                bounds_error=False)\n",
    "    else : \n",
    "        finterp = interpolate.RegularGridInterpolator([ds_ssh.time.values[0:25],ds_ssh.latitude.values,ds_ssh.longitude.values],\n",
    "                                                ds_ssh[var].values[0:25],\n",
    "                                                bounds_error=False)\n",
    "    \n",
    "    return finterp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_satellite(track,new_time_array,interp,var):\n",
    "    \n",
    "    ssh_interp = interp(np.transpose([track.time.values, track.latitude.values,track.longitude.values]))\n",
    "\n",
    "    #if var is \"ssh_cor\", renaming it into \"ssh\" in the netcdf file \n",
    "    if var == \"ssh_cor\":\n",
    "        var = \"ssh\"\n",
    "\n",
    "    ds = xr.Dataset(data_vars={var:(('time'),ssh_interp[np.invert(np.isnan(ssh_interp))]),}, # don't forget to add 'time',\n",
    "                    coords={'time':('time',new_time_array[np.invert(np.isnan(ssh_interp))]),\n",
    "                            'latitude':('time',track.latitude.values[np.invert(np.isnan(ssh_interp))]),\n",
    "                            'longitude':('time',track.longitude.values[np.invert(np.isnan(ssh_interp))])},\n",
    "                    )\n",
    "    \n",
    "    ds[var] = ds[var].assign_attrs({\"description\":dic_attrs[var],\n",
    "                           \"units\":\"[m]\"})\n",
    "    \n",
    "    return ds \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_folder = dict({\"crossover_CCS\":\"2023b_SSHmapping_HF_Crossover_California\",\"crossover_centerpacific\":\"2023c_SSHmapping_HF_Crossover_CenterPacific\",\\\n",
    "                    \"crossover_hawaii\":\"2023d_SSHmapping_HF_Crossover_Hawaii\",\"hawaii\":\"2023e_SSHmapping_HF_Hawaii\"})\n",
    "\n",
    "def create_dataset (date,omit_next_step=False):\n",
    "\n",
    "    for sat in [\"alg\",\"c2\",\"j3\",\"s3a\",\"s3b\"]:\n",
    "        \n",
    "        track, new_time_array = open_satellite_data(date,sat)\n",
    "\n",
    "        list_ds = []\n",
    "\n",
    "        for var in list_variables : \n",
    "            finterp = open_model_data(date,var,omit_next_step)\n",
    "            list_ds.append(interp_satellite(track,new_time_array,finterp,var))\n",
    "            del finterp\n",
    "        \n",
    "        ds = xr.merge(list_ds)\n",
    "\n",
    "        try:\n",
    "            ds.to_netcdf(f\"/bettik/bellemva/ocean_data_challenge/{name_folder[zone]}/dc_obs_nadirs/\"+sat+\"/SSH_NADIR_\"+date.astype('str')+\".nc\",\n",
    "                        encoding = {\"time\" : {'units' : \"nanoseconds since 2012-01-01 00:00:00.000000000\"}})\n",
    "        except ValueError:\n",
    "            print(\"Na data for \"+sat+\" in that zone for \"+date.astype('str'))\n",
    "\n",
    "        del track, ds, new_time_array \n",
    "    \n",
    "    print(date,\"done\")\n",
    "\n",
    "    return None "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. - Track interpolating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-08-27 done\n",
      "2012-08-28 done\n",
      "2012-08-29 done\n",
      "2012-08-30 done\n",
      "2012-08-31 done\n",
      "2012-09-01 done\n",
      "2012-09-02 done\n",
      "2012-09-03 done\n",
      "2012-09-04 done\n",
      "2012-09-05 done\n",
      "2012-09-06 done\n",
      "2012-09-07 done\n",
      "2012-09-08 done\n",
      "2012-09-09 done\n",
      "2012-09-10 done\n",
      "2012-09-11 done\n",
      "2012-09-12 done\n",
      "2012-09-13 done\n",
      "2012-09-14 done\n",
      "2012-09-15 done\n",
      "2012-09-16 done\n",
      "2012-09-17 done\n",
      "2012-09-18 done\n",
      "2012-09-19 done\n",
      "2012-09-20 done\n",
      "2012-09-21 done\n",
      "2012-09-22 done\n",
      "2012-09-23 done\n",
      "2012-09-24 done\n",
      "2012-09-25 done\n",
      "2012-09-26 done\n",
      "2012-09-27 done\n",
      "2012-09-28 done\n",
      "2012-09-29 done\n",
      "Na data for c2 in that zone for 2012-09-30\n",
      "2012-09-30 done\n",
      "2012-10-01 done\n",
      "2012-10-02 done\n",
      "2012-10-03 done\n",
      "2012-10-04 done\n",
      "2012-10-05 done\n",
      "2012-10-06 done\n",
      "2012-10-07 done\n",
      "2012-10-08 done\n",
      "2012-10-09 done\n",
      "2012-10-10 done\n",
      "2012-10-11 done\n",
      "2012-10-12 done\n",
      "2012-10-13 done\n",
      "2012-10-14 done\n",
      "2012-10-15 done\n",
      "2012-10-16 done\n",
      "2012-10-17 done\n",
      "2012-10-18 done\n",
      "2012-10-19 done\n",
      "2012-10-20 done\n",
      "2012-10-21 done\n",
      "2012-10-22 done\n",
      "2012-10-23 done\n",
      "2012-10-24 done\n",
      "2012-10-25 done\n",
      "2012-10-26 done\n",
      "2012-10-27 done\n"
     ]
    }
   ],
   "source": [
    "dates = np.arange(np.datetime64(\"2012-08-27\"),np.datetime64(\"2012-10-28\"))\n",
    "# dates = np.arange(np.datetime64(\"2012-05-01\"),np.datetime64(\"2012-08-28\"))\n",
    "\n",
    "for d in dates : \n",
    "    omit_next_step = False \n",
    "    if d == np.datetime64(\"2012-10-27\"):\n",
    "        omit_next_step = True\n",
    "    create_dataset(d,omit_next_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(np.datetime64(\"2012-07-31\"),omit_next_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xr.open_dataset(f\"/bettik/bellemva/ocean_data_challenge/{name_folder[zone]}/dc_obs_nadirs/alg/SSH_NADIR_2012-07-14.nc\")\n",
    "test\n",
    "\n",
    "plt.scatter(test.longitude,test.latitude,c=test.ssh_bm)\n",
    "#plt.plot(test.ssh_it1,label=\"IT\")\n",
    "#plt.plot(test.ssh_bm,label=\"BM\")\n",
    "#plt.plot(test.ssh,label=\"TOT\")\n",
    "#plt.plot(test.ssh-test.ssh_bm,label=\"DIFF\")\n",
    "\n",
    "#plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude = np.arange(180,245.01,1/48)\n",
    "latitude = np.arange(10,45.01,1/48)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,4),dpi=200,subplot_kw={\"projection\": ccrs.PlateCarree(central_longitude=0.)})\n",
    "\n",
    "ax.set_extent([-180, -115,10, 45],crs=ccrs.PlateCarree())\n",
    "map_diff = ax.scatter(ds_alg.longitude.values,\n",
    "                      ds_alg.latitude.values,\n",
    "                      c=ds_alg.ssh_cor.values,cmap=\"Spectral\",vmin=-1,vmax=1)\n",
    "\n",
    "ax.add_feature(cfeature.LAND,color=\"lightgrey\",zorder=1)\n",
    "ax.add_feature(cfeature.OCEAN,color=\"black\",zorder=0)\n",
    "ax.coastlines(lw=0.5)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Altika OSSE tracks\")\n",
    "\n",
    "gridlines = ax.gridlines(\n",
    "    alpha=0.3,\n",
    "    color=\"white\",\n",
    "    draw_labels=True,\n",
    "    xlocs=np.arange(-180,-115,10),\n",
    "    ylocs=np.arange(10,45,5),\n",
    "    # xformatter=cartopy.mpl.ticker.LongitudeFormatter(zero_direction_label=True,),\n",
    ")\n",
    "gridlines.right_labels = False\n",
    "gridlines.top_labels  = False\n",
    "gridlines.xlabel_style = {'size': 11}\n",
    "gridlines.ylabel_style = {'size': 11}\n",
    "ax.set_aspect(\"equal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_massh_bis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
